\section{Introduction}

Our society has entered a data-centric era and a huge amount of data are transferred and processed on the Internet. Among them, multimedia data, such as image and video, has become one of the major data types being processed. As analyzed by CISCO Inc., video data occupies 50\% of network traffic in 2011 and will increase to 90\% in 2013~\cite{CISCO2011}.  According to a report~\cite{youtube2009}, as one of the most popular video sharing sites, more than 20-hour new videos are uploaded to \emph{YouTube} every minute. Moreover, as two most popular photo sharing sites, \emph{Facebook} and \emph{Flickr} host billions of user-uploaded images respectively.

With the rapid increase of multimedia data, one of the most significant challenges is to understand and interpret such a huge amount of multimedia data. Currently, more and more retrieval applications are emerging to process these multimedia data, such as video recommendation~\cite{videorecommendation2007}, travel guidance systems~\cite{travelguidance2010} and content-based TV copy identification~\cite{tvidentify2003}. In these systems, a fundamental step is to extract feature information from images. 

Image features can be divided into two domains -- local features and global features. Local features are more precise and robust when comparing to global features. Thus they are widely used in most of image retrieval systems. But the computation of local features suffers great overhead due to thousand of features existed in one image, which leads to a great challenge for real-time processing. For example, SIFT~\cite{Lowe2004SIFT} and SURF~\cite{Bay2006SURF}, two popular image retrieval algorithms~\cite{Mikolajczyk2005Evaluation}\cite{Bauer2007Evaluation}, can only achieve a speed of about three images per second, when the computation are processed on a general-purpose processor.

In general, there exist three major computation phases when processing local image features in a typical image retrieval system. First, the system detect all feature points from images. Then, with some specific formats and algorithms, each feature point is described as a high dimension vector. At last, all extracted feature are compared to each other according to the distance of their vectors.

According to a previous research~\cite{Fang2011ispass}, the computation of feature describing are obviously greater than the feature detecting in the SURF algorithm, which is caused by the great amount of local features to be described in one image. Furthermore, in a realistic image retrieval system, the performance is dominated by the number of features in the database.

So, it's possible and necessary to improve the performance of the whole system by the reduction of local features extracted from each image. In this paper, we present a algorithm named LFSR (Local Feature based Salient Region) to eliminate unimportant local features efficiently with no obvious precision loss for a image retrieval system.

The main idea of LFSR algorithm is extracting salient regions of images and only describing the local features in those regions. Without involving any other salient region algorithm, it is only based on the feature points extracted from the first phase of a typical local feature algorithm. This approach has two remarkable advantages: no additional computation for salient region detection; totally integrated with local feature algorithm to compute the salient region efficiently. The details of LFSR can be found in Section 2. 

We have evaluated LFSR against a stat-of-the-art salient region algorithm. The evaluation results show that our approach has a much better performance with comparable precision and recall. Furthermore, withing a realistic image retrieval system, our evaluation shows that LFSR can help to improve both performance and accuracy.