\section{Introduction}
\label{sec:introduction}

Our society has entered a data-centric era with a huge amount of data being transferred and processed on the Internet. Among them, multimedia data, such as image and video, has become one of the major data types. As analyzed by CISCO Inc., video data occupies 50\% of network traffic in 2011 and will increase to more than 90\% in 2013~\cite{index2010forecast}. According to a report~\cite{jansohn2009detecting}, as one of the most popular video sharing sites, more than 60-hour new videos are uploaded to \emph{YouTube} every minute. Moreover, \emph{Facebook} and \emph{Flickr} have hosted billions of user-uploaded photos respectively.

With the rapid increase of multimedia data, one of the most significant challenges is to understand and interpret such a huge amount of multimedia data. Currently, more and more retrieval applications are emerging to process these multimedia data, such as video recommendation~\cite{videorecommendation2007}, travel guidance~\cite{travelguidance2010} and content-based TV copy identification~\cite{tvidentify2003}. 

Based on feature types, these multimedia retrieval systems can be classified into two categories: global feature-based and local feature-based. Global feature algorithms tend to describe an image\footnote{Since video retrieval applications also use image retrieval algorithms to extract the features for their frames, these applications will be considered as special image retrieval applications in the following parts of this paper.} as a whole, such as contour representations, shape descriptors and texture features. Although global feature algorithms can achieve a high processing speed, their accuracy cannot be guaranteed. On the other hand, {\lfea}s represent  an image with hundreds of feature points, such as SIFT~\cite{lowe1999object,lowe2004distinctive} and SURF~\cite{Bay2006SURF,Evans20009OpenSURF}. 

Compared to global feature algorithms, {\lfea}s are more robust, both scale-invariant and rotation-invariant~\cite{mikolajczyk2005performance}\cite{Bauer2007Evaluation}. However, even the SURF algorithm, an optimized algorithm derived from SIFT, is still very slow. While executed on a 3.3GHz Core i7 CPU~\cite{adaptivepipelineicpp2012}, it can only achieve a processing speed of less five frames per second, far from the real-time requirement. Moreover, since extracting hundreds of high-dimensional feature points for each image, it generally requires several hundred KB storage space to save the feature points of an image. With a dramatically increasing of image or video amount on the Internet, it puts a great pressure on real-time processing and large-scale data storage.

In general, a {\lfea} consists of two stages: feature detection and feature description. In feature detection stage, feature points in an image are located. And in the description stage, each point is described into a high-dimensional vector based on the information around it. As analyzed in \cite{adaptivepipelineicpp2012}, description stage is more time-consuming. Therefore, less feature points means less processing time and less storage space. Salient region techniques~\cite{cheng2011global,achanta2009frequency,itti1998model}, which picks up visual attention parts from an image, can be used to reduce the amount of feature points through marking the features outside the region as unimportant and eliminating them. However, prior salient region algorithms cannot satisfy the requirements due to their characteristics. The major constraints come from two aspects. First, to provide precise region boundaries, these prior algorithms generally include complex computation, which leads to slow processing speed. Second, a lot of local features locate on objects' edges and corners where are also the boundaries of salient regions. Therefore, precise salient region algorithms also means the feature points in the boundary would be discarded, which will degree the retrieval accuracy. 

To overcome these obstacles, we have a comprehensive analysis on the relation between the salient region and the local features in an image. In the analysis, we find that the distribution of local features in salient regions is denser compared to that of outside the regions, which we call salient features. Moreover, the feature points in the boundary of an object is also important for accuracy. Based on these observations, we first design an approximate salient region algorithm. It detects the salient regions through simple computing the distribution of local feature points. Due to no complex computation for precise boundary location, it is very fast. No precise boundary also guarantee the accuracy because the important feature points in the boundary are not discarded. Then, we implement a Salient Region conducted Local Feature algorithm~({\sys}), which employs salient regions to eliminate unimportant local features to accelerate processing speed and reduce storage requirement.  Experimental results show when compared to the original {\lfea}s, {\sys} achieves an overall 1.6X speedup with about 58\% storage reduction and 7\% accuracy loss.

In summary, this paper makes the following contributions:
\squishlist
\item An approximate salient region algorithm, which is efficient and accurate enough to be combined with {\lfea}s to accelerate the processing speed and reduce storage space.

\item A salient region conducted local feature algorithm that is 1.6X faster with only 42\% storage space requirement and 7\% accuracy loss.
\squishend

The rest of the paper is organized as follows. Section~\ref{sec:observation} presents the base motivation and observation for our algorithm. Section~\ref{sec:algorithm} discusses the detailed algorithm. Several evaluations are presented in Section~\ref{sec:evaluation}. We conclude the paper in Section~\ref{sec:conclusion}.