\section{Evaluation}
\label{sec:evaluation}

In this section, we first present some precision comparisons. Then, to show the performance improvement of local feature descriptor by using LFSR, an evaluation is also performed on a LFSR enabled SURF descriptor.

\subsection{Experimental Comparison}
\label{sec:evaluation_comparison}

\begin{table*}[!t]
\begin{center}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
 & Precision & Recall & F score & Reduction Efficiency & Process Time(s) \\
\hline\hline
FTSR & 0.74 & 0.59 & 0.68 & 30\% & 2828 \\
LFSR & 0.52 & 0.59 & 0.55 & 42\% & 3.2 \\
\hline
\end{tabular}
\end{center}
\caption{Comparison between FTSR and LFSR.}
\label{tab:comparison}
\end{table*}

As mentioned in Section~\ref{sec:introduction}, we target to design a algorithm for local feature reduction, and salient region detection is just suitable for that task. To achieve a good performance, we present LFSR instead of directly using any existed salient region algorithm. Although LFSR is only a approximate algorithm, we are still interested in evaluating its precision against others. Here we compare LFSR with a previous research named FTSR (Frequency-Tuned Salient Region) by Achanta et al.~\cite{achanta2009frequency}. FTSR is a state-of-the-art salient region algorithm with a C++ implementation which is easy to compare the performance. To work with local feature descriptor, FTSR here should perform segmentation on its saliency map before doing feature reduction. It means in our evaluation the process time of FTSR includes not only the saliency map generation but also the segmentation processing.

Since we only focus on local features, our evaluation should differ from other related researches: the precision and recall are given according to the results of local feature reduction, not the precise salient region boundary. The evaluated dataset is also provided by Achanta et at.~\cite{achanta2009frequency}, which is a subset of the public database by Liu et at.~\cite{liu2011learning}. As input, we generate local features for all testing SURF descriptor~\cite{evans2010opensurf}. 

As shown in Table~\ref{tab:comparison}, LFSR gets a lower precision and a same recall, with a not bad F score. Considering the application scenario of LFSR, the precision here is not much important, since the final match result is only based on the distance between feature vectors. Furthermore, we also presents the reduction efficiency of each algorithm in column 5, which refers to the proportion of the left local features after a reduction. The results shows that both of them can help to eliminate more than half of the original features.

To evaluate the performance of these two algorithms, we implement LFSR and FTSR both in C++ and run them on a Intel Quad Core 2.4Ghz CPU. The result shows that the well optimized FTSR costs 2828 seconds to compute all 1000 images, while the similar implementation of LFSR only costs 3.2 seconds. The performance result of LFSR is very impressive but not surprising, because the computation of LFSR is really simple and straightforward.

\subsection{SURF Descriptor Integration}
\label{sec:evaluation_integration}

LFSR is designed to improve the performance of local feature descriptor. To evaluate whether LFSR satisfies this design purpose, we integrate our algorithm into the OpenSURF~\footnote{http://www.chrisevansdev.com/computer-vision-opensurf.html} to see the actual effects. The salient region detection is carefully added between the detection stage and the description stage. It means LFSR can reuse the computation results directly from the detection stage. After the reduction of LFSR, the computation of the description stage should be much smaller, since it's only related to the amount of local features.

Furthermore, we also implement a whole image retrieval system for evaluation. The system first builds a VOC-Tree~\cite{VOCTree2006} by using SURF feature vectors extracted from image datasets. Then, each incoming query image is transfered into SURF vectors too and compared in that VOC-Tree. At last, the found top similar images would be reordered by using RANSAC~\cite{ransac1981}. To involve LFSR, we just replace the original SURF with a LFSR enabled version.

The evaluation input is an image retrial dataset by Nist\'er et al.~\cite{nister-stewenius-cvpr-2006} with 10200 VGA ($640\times480$ pixels) photos. And the whole experiment is performed on a server with a Intel Quad Core i7 3.4Ghz CPU and 4GB RAM. Table~\ref{tab:integration} shows the final performance results. Compared to the original SURF algorithm, LFSR help to improve the performance by 1.6X. And by reducing local features, the whole image retrieval system gains a almost 2X speedup in both building and query phase.

\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Algorithm & Detecting & Building & Query \\
\hline\hline
SURF & 0.15 & 0.06 & 0.54 \\
SURF-LFSR & 0.09 & 0.03 & 0.34 \\
\hline\hline
SIFT & 0.54 & 0.33 & 1.65 \\
SIFT-LFSR & 0.33 & 0.12 & 0.77 \\
\hline
\end{tabular}
\end{center}
\caption{Average time for computing each image. Detecting refers to local feature descriptor time. Building refers to VOC-Tree building time. Query includes VOC-Tree query time and RANSAC time.}
\label{tab:integration}
\end{table}